# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "11.7"

  # a list of ubuntu apt packages to install
  system_packages:
    - "ffmpeg"
    - "libsndfile1"
    - "git"


  # python version in the form '3.8' or '3.8.12'
  python_version: "3.10"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "ruamel-yaml==0.18.5"
    - "wget==3.2"
    - "kornia==0.7.0"
    - "braceexpand==0.1.7"
    - "webdataset==0.2.75"
    - "wandb==0.16.0"
    - "pytorch-lightning==2.1.1"
    - "einops==0.7.0"
    - "h5py==3.10.0"
    - "transformers==4.30.2"
    - "ftfy==6.1.1"
    - "pandas==2.1.3"
    - "matplotlib==3.8.1"
    - "taming-transformers-rom1504==0.0.6"
    - "ipdb==0.13.13"
    - "librosa==0.9.1"
    - "git+https://github.com/haoheliu/passt_hear21.git"
    - "git+https://github.com/haoheliu/audioldm_eval.git"



  # run bash commands:
  # run:
  #  - echo "export PYTHONPATH=/src/AudioLDM-training-finetuning" >> ~/.bashrc
  #   - curl -sSL https://install.python-poetry.org | python3 -
  #   - export PATH="/root/.local/bin:$PATH" && poetry config virtualenvs.create false   
  #   - git clone https://github.com/haoheliu/AudioLDM-training-finetuning.git
  #   - export PATH="/root/.local/bin:$PATH" && cd AudioLDM-training-finetuning && poetry install --no-root



# predict.py defines how predictions are run on your model
predict: "predict.py:DummyPredictor"

image: "afeka_dl.3"
